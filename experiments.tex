\documentclass[12pt, notitlepage]{article}

\usepackage{color}		% use colors
\usepackage{url}		% bibliography: inserting an url
\usepackage{amssymb}	% usual
\usepackage{listings}	% displaying bash command lines
\usepackage{enumitem}	% no separation between items in itemize
						% need to install texlive-extra

\lstset{
	language=bash,
	}

\begin{document}
\bibliographystyle{plain}

\title{Experimenting on HTTP/2}
\maketitle

\begin{abstract}
This short paper aims at explaining how to compare the performances
of HTTP/1.1 and HTTP/2.
The metric used to evaluate the performances is the Page Loading Time
(PLT) as defined in ~\cite{w3c}.
To sum it up, the PLT is the time elapsed between the moment clients
enter a URL in their search bar and the moment the webpage requested is
fully displayed in the browser window.
\end{abstract}

\section{Introduction}
% Only support of Ubuntu Trusty in the experiments
We analyze two versions of the HTTP protocol: HTTP/1.1 and HTTP/2.
For both protocols, we study two variants: a cleartext one and an
encrypted other. We end up with four protocols summarized as follows:
\begin{itemize}[noitemsep]
	\item[--] HTTP/1.1 cleartext $\to$ HTTP;
	\item[--] HTTP/1.1 secure $\to$ HTTPS;
	\item[--] HTTP/2 cleartext $\to$ h2c;
	\item[--] HTTP/2 secure $\to$ h2.
\end{itemize}
\newpage

\section{Setting up the experiments}
To compare the page loading times we need to set up: 
\begin{itemize}[noitemsep]
\item[--] a server, to provide the webpages;
\item[--] a client, to request and load them.
\end{itemize}

The client and the server used throughout our experiments need to be the
same for all protocols -- else our results would be biased. How should we
choose them?

\subsection{Setting up a server}
Why do we need to set up a server when there are thousands of webservers
already delivering contents on the Internet? Well, the problem is that
those servers only use three of the aforementioned protocols: HTTP, HTTPS
and h2. But h2c is never used.
That is why we need to setup a server that will serve content on the 
four protocols. 
Looking at the list of available 
implementations on~\cite{implem}, only one server fits these requirements:
H2O~\cite{h2o}.\\

% TODO: Create an Appendix explaining how to set up H2O on ubuntu Trusty
If you wish to better understand how the setting up of H2O works, you
can look at~\cite{h2o}. However, we already did all the job for you: a
server is up and running at the IP address 161.106.2.57 (h2-14).
But we still have to choose which content we want to 
deliver: we decided to take the most consulted websites on
Alexa~\cite{alexa} and to clone the main pages (Google, Facebook, Youtube,
etc) on our own machine.
Right now, this server is just waiting for you to
retrieve its content. And the only thing you need to do that is a client.

\subsection{Setting up a client}

The client is just a browser able to talk all four of the above 
protocols. Currently, no browser provides h2c (HTTP/2 cleartext) support;
so we picked Chromium (which already talked HTTP, HTTPS and h2) and
slightly modified it so that it could talk h2c.\\

\newpage
Here again, no need to build Chromium yourself, because we have the
modified binaries available at~\cite{chromium}. Feel free to download and
install this package on your latest Ubuntu version (no other OS support at 
the moment). Here is how you can make it work:
\textbf{sudo dpkg -i name\_\_of\_\_the\_\_package.deb}
(You might also have to \textbf{sudo apt-get build-dep chromium-browser}).\\

If you want to use direct clear text HTTP/2 (h2c) with Chromium, use the
following command line options:
\textbf{chromium-browser --enable-spdy4 --use-spdy=no-ssl}
This should will launch Chromium with only h2c activated. You can
check out the status of HTTP/2 connections at chrome://net-internals/\#spdy
(SPDY is the name of HTTP/2 inside the Chromium browser).

\section{Tool for experimenting}
% Installation for Ubuntu Trusty Tahr only
The tool to test the page load time performances is available at
~\cite{load_times}. Go to the same workplace where you cloned chromium
and clone this other repository with the following command line: 
\begin{lstlisting}
  $ git clone https://github.com/desaxce/load_times
  $ sudo apt-get install build-essential gnuplot gnuplot-x11
\end{lstlisting}
\vspace*{0.5cm}

Now you are all set. You can try: 
\begin{lstlisting}
$ make
$ ./test --ip 161.106.2.57 -s 30 -t 1 -r leopard.html
\end{lstlisting}

\vspace*{0.5cm}
This will: 
\begin{itemize}[noitemsep]
\item[--] retrieve the webpage leopard.html at the address 
161.106.2.57;
\item[--] wait exactly 30 seconds for the page to load;
\item[--] request the webpage exactly one time for each\footnote{If you are
behind a proxy some protocols might be filtered (typically h2c)}
protocol.
\end{itemize}

The results are written to 0.0.default.161.106.2.57.txt ("0.0" stands for
0\% delay and 0\% packet loss: those are parameters you can change). To
compare the page loading times, you simply have to execute:
\begin{lstlisting}
$ ./hist_total.gnu 0.0.default.161.106.2.57.txt
\end{lstlisting}
For more information about this small utility, type:
\begin{lstlisting}
$ ./test
\end{lstlisting}

\newpage

\section{Results}
I cloned the following websites:
google.com, youtube.com, yahoo.com, baidu.com, wikipedia.org, amazon.com, qq.com, taobao.com, sina.com.cn, hao123.com, weibo.com, yahoo.co.jp, yandex.ru, tmall.com, ebay.com, bing.com, sohu.com.\\

And ran my experiments on these websites over a simulated network with 
various network characteristics (delay and losses).
Here are some graphs representing the page loading times of several
websites using one of the four protocols each time:

\section{Building Chromium from source}

First install the following Debian repository
\footnote{https://launchpad.net/~saiarcot895/+archive/ubuntu/chromium-dev/+packages}.
Second, dpkg-source chromium-browser.
Third, install the depot tools from the Chromium projects
\footnote{http://www.chromium.org/developers/how-tos/install-depot-tools}.

\subsection{HTTP/2 in the clear}
In order to have a Chromium version with clear text HTTP/2, simply
modify the file in src/chrome/browser/io\_thread.cc and change the lines where
the option kDisableSSL is used:

\textbf{\} else if (option == kDisableSSL) \{}\\
\hspace*{1cm}\textbf{globals\_\_$\rightarrow$spdy\_\_default\_\_protocol.set(net::kProtoSPDY31);}\\

\textit{into}\\

\textbf{\} else if (option == kDisableSSL) \{}\\
\hspace*{1cm}{\textbf{globals\_\_$\rightarrow$spdy\_\_default\_\_protocol.set(net::kProtoSPDY4\_\_14);}\\


\subsection{Logging the loading times}
To store the times, you have to modify two files. First,
src/third\_\_party/WebKit/Source/core/loader/DocumentLoadTiming.cpp:
add the line\\
\hspace*{1cm}\textbf{fprintf(stderr, "setNavigationStart = \%lf$\backslash$n", navigationStart);}\\
in the method named setNavigationStart.\\

\hspace*{-0.7cm}And also add the method:\\
\textbf{void DocumentLoadTiming::markLoadEventEnd() \{}\\
\hspace*{1cm}\textbf{m\_loadEventEnd = monotonicallyIncreasingTime();}\\
\hspace*{1cm}\textbf{fprintf(stderr, "markLoadEventEnd = \%lf$\backslash$n", loadEventEnd());}\\
\textbf{\}}\\ 

Second, src/third\_\_party/WebKit/Source/core/loader/DocumentTiming.h:
Change the prototype of the method markLoadEventEnd to
\textbf{void markLoadEventEnd();}\\



You can browse the Chromium source code at
\url{https://code.google.com/p/chromium/codesearch#} for more informations.

\section{Machines available}

\hspace*{0.6cm}For local tests (Issy-les-Moulineaux - Yiping Chen): via SSH, \textbf{@:} 172.20.36.138, \textbf{login:} smcd, \textbf{pwd:} smcd.\\

For global tests (Val-de-Reuil - Frédéric Fieau): via SSH, \textbf{@:} 161.106.2.57, \textbf{login:} root, \textbf{pwd:} HFT:-p.\\
\textbf{login:} debianuser, \textbf{pwd:} DEB:-p.\\

To connect on the outside machine, you need to add the following line in the config file in $\sim$/.ssh:\\
\textbf{ProxyCommand nc -x Goodway:1080 \%h \%p}


\newpage
\bibliography{references}
\end{document}


